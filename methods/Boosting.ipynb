{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdc7c0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6590a4b",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9aec79",
   "metadata": {},
   "source": [
    "On travaille uniquement sur les données Wisconsin Diagnostic Breast Cancer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a0bcb7",
   "metadata": {},
   "source": [
    "## Fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0274ab3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(x):\n",
    "    return np.sort(np.random.choice(x, len(x)))\n",
    "                   \n",
    "def out_of_bag(bootstrap_sample, x):\n",
    "    return x[np.where(not bootstrap_sample in x)]\n",
    "\n",
    "def erreur_prediction(weights, pred, true_pred):\n",
    "        return np.dot(weights, pred == true_pred)\n",
    "                   \n",
    "class boosting:\n",
    "\n",
    "    def __init__(self, nb_iterations=100, model = \"decision_tree\"):\n",
    "        self.nb_iterations = nb_iterations\n",
    "        self.model = model\n",
    "        self.pred = []\n",
    "        self.trees = []\n",
    "        self.alpha = []\n",
    "        self.weights = [] #D_i\n",
    "    \n",
    "    #epsilon_t\n",
    "    def erreur(self, y, y_pred):\n",
    "        err = 0\n",
    "        for i in range(len(y)):\n",
    "            if y[i] != y_pred[i]:\n",
    "                err += self.weights[i]\n",
    "        return err/len(y)\n",
    "        \n",
    "    def one_adaboost_iteration(self, train_data, y, n, max_depth):\n",
    "        if self.model == \"decision_tree\" :\n",
    "            one_tree = DecisionTreeClassifier(max_depth=max_depth)\n",
    "        self.trees.append(one_tree.fit(X = train_data, y=y, sample_weight=self.weights))\n",
    "        predictions = one_tree.predict(train_data)\n",
    "        \n",
    "        error_rate = self.erreur(y, predictions)\n",
    "        new_alpha = np.log((1-error_rate)/error_rate)/2\n",
    "        self.alpha.append(new_alpha)\n",
    "        for i in range(n):\n",
    "            if predictions[i] == y[i]:\n",
    "                self.weights[i] = self.weights[i] * np.exp(-new_alpha)\n",
    "            else:\n",
    "                self.weights[i] = self.weights[i] * np.exp(new_alpha)\n",
    "        self.weights = self.weights/sum(self.weights) #Normalisation\n",
    "            \n",
    "        \n",
    "    def fit(self, train_data, y, max_depth=1):\n",
    "        if not isinstance(y, np.ndarray):\n",
    "            y = np.array(y)\n",
    "        n = np.shape(train_data)[0]\n",
    "        self.weights = np.ones(n)/n\n",
    "        for i in range(self.nb_iterations):\n",
    "            self.one_adaboost_iteration(train_data, y, n, max_depth)\n",
    "            \n",
    "    def votes(self, predictions, categories, seuil=0.5):\n",
    "        nb_individus = np.shape(predictions)[1]\n",
    "        nb_classifieurs = np.shape(predictions)[0]\n",
    "        res_votes = []\n",
    "\n",
    "        for j in range(nb_individus):\n",
    "            res_votes.append(self.vote(predictions[j], categories, nb_classifieurs, seuil))\n",
    "\n",
    "        return res_votes\n",
    "\n",
    "    def vote(self, predictions, categories, nb_classifieurs, seuil=0.5):\n",
    "        nb_votes = np.zeros(len(categories))\n",
    "        for i in range(nb_classifieurs):\n",
    "            for c in range(len(categories)):\n",
    "                if predictions[i] == categories[c]:\n",
    "                    nb_votes[c] += self.alpha[i]\n",
    "        nb_votes = nb_votes/sum(self.alpha)\n",
    "\n",
    "        temp = []\n",
    "        for c in range(len(categories)):\n",
    "            if (nb_votes[c] >= seuil):\n",
    "                temp.append(categories[c])\n",
    "        if temp == []:\n",
    "            return \"NA\"\n",
    "        else:\n",
    "            return temp\n",
    "\n",
    "    def predict(self, new_data, categories, seuil=0.5):\n",
    "        self.pred = []\n",
    "        for t in self.trees:\n",
    "            self.pred.append(t.predict(new_data))\n",
    "        self.pred = pd.DataFrame(self.pred)\n",
    "        return self.votes(self.pred, categories= categories, seuil=seuil)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f44376b",
   "metadata": {},
   "source": [
    "# Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "347d4afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>V29</th>\n",
       "      <th>V30</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      V1     V2      V3      V4       V5       V6      V7       V8      V9  \\\n",
       "0  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001  0.14710  0.2419   \n",
       "1  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869  0.07017  0.1812   \n",
       "2  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974  0.12790  0.2069   \n",
       "3  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414  0.10520  0.2597   \n",
       "4  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980  0.10430  0.1809   \n",
       "\n",
       "       V10  ...    V22     V23     V24     V25     V26     V27     V28  \\\n",
       "0  0.07871  ...  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654   \n",
       "1  0.05667  ...  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
       "2  0.05999  ...  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n",
       "3  0.09744  ...  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n",
       "4  0.05883  ...  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n",
       "\n",
       "      V29      V30  Class  \n",
       "0  0.4601  0.11890      2  \n",
       "1  0.2750  0.08902      2  \n",
       "2  0.3613  0.08758      2  \n",
       "3  0.6638  0.17300      2  \n",
       "4  0.2364  0.07678      2  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_data = pd.read_csv(\"phpAmSP4g.csv\")\n",
    "cancer_categories = np.unique(cancer_data[\"Class\"])\n",
    "y = cancer_data[\"Class\"]\n",
    "X = cancer_data.drop(labels=[\"Class\"], axis=1)\n",
    "cancer_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2193b458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    62.7\n",
       "2    37.3\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(100*cancer_data[\"Class\"].value_counts()/np.shape(cancer_data)[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca4b7f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V1       float64\n",
       "V2       float64\n",
       "V3       float64\n",
       "V4       float64\n",
       "V5       float64\n",
       "V6       float64\n",
       "V7       float64\n",
       "V8       float64\n",
       "V9       float64\n",
       "V10      float64\n",
       "V11      float64\n",
       "V12      float64\n",
       "V13      float64\n",
       "V14      float64\n",
       "V15      float64\n",
       "V16      float64\n",
       "V17      float64\n",
       "V18      float64\n",
       "V19      float64\n",
       "V20      float64\n",
       "V21      float64\n",
       "V22      float64\n",
       "V23      float64\n",
       "V24      float64\n",
       "V25      float64\n",
       "V26      float64\n",
       "V27      float64\n",
       "V28      float64\n",
       "V29      float64\n",
       "V30      float64\n",
       "Class      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a93d836",
   "metadata": {},
   "source": [
    "C'est un problème de classification a deux classes déséquilibré. Nous avons 30 variables numériques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69593452",
   "metadata": {},
   "source": [
    "## Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c60cd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "boost_model = boosting(nb_iterations=100, model = \"decision_tree\")\n",
    "boost_model.fit(train_data = X_train, y = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4d2da82",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = boost_model.predict(new_data= X_train, categories = cancer_categories, seuil = 0.5)\n",
    "y_chap = np.array(pred)\n",
    "acc_train = accuracy_score(y_train, y_chap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a540e84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2], [2], [1], [1], [2], [2], [2], [1], [1]]\n"
     ]
    }
   ],
   "source": [
    "pred = boost_model.predict(new_data= X_test, categories = cancer_categories, seuil = 0.5)\n",
    "print(pred[1:10])\n",
    "y_chap = np.array(pred)\n",
    "acc_test = accuracy_score(y_test, y_chap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "429c0baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train data = 1.000\n",
      "Accuracy on test data = 0.959\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on train data = %0.3f\"%acc_train)\n",
    "print(\"Accuracy on test data = %0.3f\"%acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce1b629",
   "metadata": {},
   "source": [
    "Les accuracy sont satisfaisantes. On s'attendait à une plus grande erreur de généralisation car les modèles de boosting ont tendances à apprendre \"par coeur\" les données d'apprentissage ce qui peut provoquer l'apparition d'un grand biais à cause d'un phénomène de sur-apprentissage. \n",
    "Ce n'est pas le cas pour cette instance du modèle de boosting qui semble avoir formulé des hypothèses cohérentes. Cela peut être dû a un jeu de données facile à apprendre ou grâce a de la chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c6e8d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train data : \n",
      "\t -mean = 0.590\n",
      "\t -standard deviation = 0.404\n",
      "Accuracy on test data : \n",
      "\t -mean = 0.572\n",
      "\t -standard deviation = 0.388\n"
     ]
    }
   ],
   "source": [
    "acc_train = []\n",
    "acc_test = []\n",
    "for i in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    boost_model = boosting(nb_iterations=100, model = \"decision_tree\")\n",
    "    boost_model.fit(train_data = X_train, y = y_train)\n",
    "    \n",
    "    pred = boost_model.predict(new_data= X_train, categories = cancer_categories, seuil = 0.5)\n",
    "    y_chap = np.array(pred)\n",
    "    acc_train.append(accuracy_score(y_train, y_chap))\n",
    "    \n",
    "    pred = boost_model.predict(new_data= X_test, categories = cancer_categories, seuil = 0.5)\n",
    "    y_chap = np.array(pred)\n",
    "    acc_test.append(accuracy_score(y_test, y_chap))\n",
    "    \n",
    "print(\"Accuracy on train data : \")\n",
    "print(\"\\t -mean = %0.3f\"%np.mean(acc_train))\n",
    "print(\"\\t -standard deviation = %0.3f\"%np.std(acc_train))\n",
    "\n",
    "print(\"Accuracy on test data : \")\n",
    "print(\"\\t -mean = %0.3f\"%np.mean(acc_test))\n",
    "print(\"\\t -standard deviation = %0.3f\"%np.std(acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e89ff33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.09045226130653267, 0.1306532663316583, 1.0, 1.0, 0.7311557788944724]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6ef3496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0935672514619883,\n",
       " 0.13450292397660818,\n",
       " 0.9649122807017544,\n",
       " 0.9766081871345029,\n",
       " 0.6900584795321637]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21882aa5",
   "metadata": {},
   "source": [
    "Il semblerait que la chance soit intervenu. On constate que deux instances possèdent d'excellents indicateurs de performances, tandis que les autres sont loin d'être satisfaisants. Il est possible que notre modèle n'a pas assez de liberté pour pouvoir explorer et identifier les informations pertinentes. Nous utilisions jusqu'à présent des arbres de profondeur égale a 1. Voyons ce qu'il se produit si nous utilisons des arbres de profondeur 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e62a5db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train data : \n",
      "\t -mean = 1.000\n",
      "\t -standard deviation = 0.000\n",
      "Accuracy on test data : \n",
      "\t -mean = 0.972\n",
      "\t -standard deviation = 0.011\n"
     ]
    }
   ],
   "source": [
    "acc_train = []\n",
    "acc_test = []\n",
    "for i in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    boost_model = boosting(nb_iterations=100, model = \"decision_tree\")\n",
    "    boost_model.fit(train_data = X_train, y = y_train, max_depth=2)\n",
    "        \n",
    "    pred = boost_model.predict(new_data= X_train, categories = cancer_categories, seuil = 0.5)\n",
    "    y_chap = np.array(pred)\n",
    "    acc_train.append(accuracy_score(y_train, y_chap))\n",
    "    \n",
    "    pred = boost_model.predict(new_data= X_test, categories = cancer_categories, seuil = 0.5)\n",
    "    y_chap = np.array(pred)\n",
    "    acc_test.append(accuracy_score(y_test, y_chap))\n",
    "    \n",
    "print(\"Accuracy on train data : \")\n",
    "print(\"\\t -mean = %0.3f\"%np.mean(acc_train))\n",
    "print(\"\\t -standard deviation = %0.3f\"%np.std(acc_train))\n",
    "\n",
    "print(\"Accuracy on test data : \")\n",
    "print(\"\\t -mean = %0.3f\"%np.mean(acc_test))\n",
    "print(\"\\t -standard deviation = %0.3f\"%np.std(acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d9da01",
   "metadata": {},
   "source": [
    "Nous constatons que notre hypothèse semble vérifiée : le jeu de données est facile à apprendre à condition que le modèle possède suffisamment de capacité d'exploration."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
